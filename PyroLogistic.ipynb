{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.special as ssp\n",
    "\n",
    "import pyro\n",
    "from pyro.distributions import Normal, Bernoulli\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "# for CI testing\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_linear_dataset(N, p=1, noise_std=0.01):\n",
    "    X = np.random.rand(N, p)\n",
    "    # w = 3\n",
    "    w = 3 * np.ones(p)\n",
    "    # b = 1\n",
    "    y = np.matmul(X, w) + np.repeat(1, N) + np.random.normal(0, noise_std, size=N)\n",
    "    y = y.reshape(N, 1)\n",
    "    X, y = torch.tensor(X).type(torch.Tensor), torch.tensor(y).type(torch.Tensor)\n",
    "    data = torch.cat((X, y), 1)\n",
    "    assert data.shape == (N, p + 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logistic_dataset(N, p=1, noise_std=0.01):\n",
    "    X = np.random.randn(N, p)\n",
    "    \n",
    "    w = np.random.randn(p)\n",
    "    w += 2 * np.sign(w)\n",
    "\n",
    "    y = np.round(ssp.expit(np.matmul(X, w) \n",
    "                           + np.repeat(1, N) \n",
    "                           + np.random.normal(0, noise_std, size=N)))\n",
    "    y = y.reshape(N, 1)\n",
    "    X, y = torch.tensor(X).type(torch.Tensor), torch.tensor(y).type(torch.Tensor)\n",
    "    data = torch.cat((X, y), 1)\n",
    "    assert data.shape == (N, p + 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        # p = number of features\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(p, 1)\n",
    "        self.non_linear = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.non_linear(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    # Create unit normal priors over the parameters\n",
    "    loc, scale = torch.zeros(1, p), 10 * torch.ones(1, p)\n",
    "    bias_loc, bias_scale = torch.zeros(1), 10 * torch.ones(1)\n",
    "    w_prior = Normal(loc, scale).independent(1)\n",
    "    b_prior = Normal(bias_loc, bias_scale).independent(1)\n",
    "    priors = {'linear.weight': w_prior, 'linear.bias': b_prior}\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_module = pyro.random_module(\"module\", regression_model, priors)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    lifted_reg_model = lifted_module()\n",
    "    with pyro.iarange(\"map\", N):\n",
    "        x_data = data[:, :-1]\n",
    "        y_data = data[:, -1]\n",
    "        \n",
    "        model_logits = lifted_reg_model(x_data).squeeze(-1)\n",
    "        pyro.sample(\"obs\", Bernoulli(logits=model_logits, validate_args=True), obs=y_data.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus = torch.nn.Softplus()\n",
    "\n",
    "def guide(data):\n",
    "    # define our variational parameters\n",
    "    w_loc = torch.randn(1, p)\n",
    "    # note that we initialize our scales to be pretty narrow\n",
    "    w_log_sig = torch.tensor(-3.0 * torch.ones(1, p) + 0.05 * torch.randn(1, p))\n",
    "    b_loc = torch.randn(1)\n",
    "    b_log_sig = torch.tensor(-3.0 * torch.ones(1) + 0.05 * torch.randn(1))\n",
    "    # register learnable params in the param store\n",
    "    mw_param = pyro.param(\"guide_mean_weight\", w_loc)\n",
    "    sw_param = softplus(pyro.param(\"guide_log_scale_weight\", w_log_sig))\n",
    "    mb_param = pyro.param(\"guide_mean_bias\", b_loc)\n",
    "    sb_param = softplus(pyro.param(\"guide_log_scale_bias\", b_log_sig))\n",
    "    # guide distributions for w and b\n",
    "    w_dist = Normal(mw_param, sw_param).independent(1)\n",
    "    b_dist = Normal(mb_param, sb_param).independent(1)\n",
    "    dists = {'linear.weight': w_dist, 'linear.bias': b_dist}\n",
    "    # overload the parameters in the module with random samples\n",
    "    # from the guide distributions\n",
    "    lifted_module = pyro.random_module(\"module\", regression_model, dists)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    return lifted_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, p = 500, 100\n",
    "optim = Adam({\"lr\": 0.05})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO())\n",
    "regression_model = RegressionModel(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 1.6895\n",
      "[iteration 1001] loss: 0.6626\n",
      "[iteration 2001] loss: 0.6781\n",
      "[iteration 3001] loss: 0.6591\n",
      "[iteration 4001] loss: 0.6731\n",
      "[iteration 5001] loss: 0.6768\n",
      "[iteration 6001] loss: 0.6751\n",
      "[iteration 7001] loss: 0.6663\n",
      "[iteration 8001] loss: 0.6687\n",
      "[iteration 9001] loss: 0.6735\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "data = build_logistic_dataset(N, p)\n",
    "num_iterations = 10000\n",
    "for j in range(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(data)\n",
    "    if j % (num_iterations / 10) == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / float(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[guide_mean_weight]: [[ 10.121038    -2.7254305   -0.13062297  10.248975     7.4295087\n",
      "   -3.6112792    7.7594714   10.111515     3.9126155    6.528598\n",
      "    9.058292    -6.626209    -8.619249     1.796047    -5.913176\n",
      "    0.6211253   12.51668      4.7814918   10.83625      7.074222\n",
      "    4.394132    10.678343    -9.629215     0.01682232  -7.6484423\n",
      "   -4.097059    11.537101    -4.7015104   -9.161883    -8.405314\n",
      "   -7.876971    -8.807516     3.6903944    5.4311028    4.973605\n",
      "  -13.16374     -5.419484     3.9035625    6.977791     5.290474\n",
      "    1.9047701    3.9085135    7.427295    -3.4100535  -12.355433\n",
      "    2.948364    -5.2586455    6.7773366   -9.540961     7.767003\n",
      "    7.0676947    4.4470787    8.159762    -5.3476276   -7.0261817\n",
      "    1.0553516    8.92021     -3.1246934    6.282368     4.339715\n",
      "   -0.60011244  -2.5544064   -8.166295     1.5811864    6.28793\n",
      "   -8.263433    -0.65276      3.1239996   -3.9836624    2.9059925\n",
      "   -2.2632983    9.797131    -5.4767213    1.2379887    4.2444143\n",
      "   -6.0347924    8.628869    -2.7180617   -6.474806    -5.489685\n",
      "    4.8178644   -8.492191    -3.8880944   -7.29541      9.002446\n",
      "   -5.051384    -2.5291464    5.068792     7.1228666   -6.2909617\n",
      "    5.0650373   -5.736547     2.1276875   -2.2757504    0.8781162\n",
      "    6.024431    -6.4149613    8.993063    -8.133656    -4.598557  ]]\n",
      "[guide_log_scale_weight]: [[7.4174037 7.329143  7.4401093 7.3967743 7.6655693 7.183405  6.974652\n",
      "  7.4316735 8.2074375 7.2926188 7.734045  7.612567  8.108449  7.5155683\n",
      "  7.125077  8.106752  7.6059914 7.440988  7.2874045 7.218653  7.7410703\n",
      "  7.47864   7.0576897 7.2270575 7.355012  7.114507  7.834397  7.404004\n",
      "  7.342846  7.7359815 7.547347  8.483427  8.003958  8.210482  7.502022\n",
      "  8.159425  7.8549337 7.852737  8.172219  6.632071  7.5832033 7.686139\n",
      "  8.014954  7.946409  7.497455  7.247548  7.1467495 7.1762514 7.621115\n",
      "  6.630083  7.4664483 7.0361657 7.14232   7.4819765 7.8790393 7.7233014\n",
      "  8.121825  7.3275433 6.903514  6.853735  6.9590106 8.17994   7.7776394\n",
      "  7.360657  7.899698  8.304749  7.7506895 7.1278687 7.1931877 7.405269\n",
      "  8.196785  6.960017  7.69038   6.838527  7.8755803 8.43934   7.7466974\n",
      "  8.021455  7.3442984 7.533981  8.636438  8.037658  7.2076826 7.487838\n",
      "  7.564208  7.551154  8.881983  7.7719197 7.415454  7.370503  7.042057\n",
      "  8.01057   7.478545  8.079377  8.106333  8.289263  7.994972  8.125148\n",
      "  6.920544  7.574043 ]]\n",
      "[guide_mean_bias]: [-9.833222]\n",
      "[guide_log_scale_bias]: [7.458136]\n"
     ]
    }
   ],
   "source": [
    "for name in pyro.get_param_store().get_all_param_names():\n",
    "    #print(\"[%s]: %.3f\" % (name, pyro.param(name).data.numpy()))\n",
    "    print(\"[%s]: %s\" % (name, pyro.param(name).data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Score: 284 / 500 or 0.568\n"
     ]
    }
   ],
   "source": [
    "scorecard = 0\n",
    "trainingdata = data\n",
    "for index, prediction in enumerate(torch.round(sampled_reg_model(data[:,:-1]))):\n",
    "    if prediction.item() == data[index,-1].item():\n",
    "        scorecard += 1\n",
    "print('Final Score: %s / %s or %s' %(scorecard, N, round(scorecard / N,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
